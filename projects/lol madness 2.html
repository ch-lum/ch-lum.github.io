<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Christopher Lum</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<span class="logo"><a href="../index.html" style="border: 0px;"><img src="../images/logo.png" alt="" /></a></span>
						<h1>League of Legends Madness 2!</h1>
						<p>Building a predictive model for League of Legends</p>
					</header>
				
				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="../index.html">About Me</a></li>
							<li><a href="../projects.html" class="active">Projects</a></li>
							<li><a href="..assets/documents/cv.html">CV</a></li>
							<li><a href="#footer">Contact</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<span class="image main"><img src="../images/league2banner.png" alt="" /></span>
								<div class="article"></div>
									<p><strong>June 15, 2023</strong><br>Christopher Lum</p> <!-- Date -->

									<p>Today, I played League of Legends again for the first time in forever. I don't usually play it during the school year, but I was practically to after my first EDA (Which you can see <a href=lol madness 1.html>here</a>). Today, I'll be working with the 2022 LOL database again (<a href='https://oracleselixir.com/tools/downloads'>here</a>) and I'm going to build a pro LOL coach (or someting like that).</p>

									<h2>Framing the Problem</h2>
									<p><i>What do coaches even do in esports?</i> is an age old question in Rocket League. Being much more established as an esport, I'm sure this isn't as much of an issue if League of Legends, but there is one thing that coaches do that I think I can recreate for myself. That is, draft my adc.</p>

									<p>The best way to learn from the best, is to (machine) learn from the best! So I built a multiclass classifier that will take in nineteen champions (and some additional information) in order to predict a team's botlaner. I think with this, you'd guess I played a lot of adc. Now, that's too smart for me. I only picked bot lane because I focused on bot lane duos last time I looked at this dataset. In hindsight, I probably should've picked to predict junglers (lets be real though, I was going to pick Rammus either way). I don't think anything is stopping me from using other laners though, so after I finish writing this I'll probably go ahead and retrain my model to predict for any laner. Lastly, I decided to focus on accuracy because I wanted a metric that is very intutative and there aren't any real repercussions from false positives or false negatives. Frankly, if you picked Aphelios every single time (the most played adc), you'd probably still win the same amount anyways. He's played a lot because he's good.</p>

									<h2>Baseline Model</h2>

									<p>What should I do to start? A little birdie (my friend John) is telling me to predict Jinx every time and to call it a day. While I could totally do that, no. For the record, that would have an accuracy of about 30%.</p>

									<p>For this first model, I used a random forest classifier. I decided this, because I like decision trees, and what's better than one tree, if not a forest? So now that I've settled on my estimator, here are the features I started with. Your four teammate champions, five opponent champions, the ten banned champions, and the league, and the patch. Patch is ordinal, and everything else is nominal. To start, I decided to just one hot encode all of the features. Simple enough, right? WRONG. Simple one hot encoding like this creates 2652 features. Cute! We started with a nice, round, 22 features. That's what you get when you have 162 champions, I guess.</p>

									<p>Anyways! Looking past that, the untuned random forest started with a test accuracy of 46%. That's pretty good! I think... I'm not really sure. I don't really know how high this can get. My friend thinks that he can get about 30% himself (<i>what if I tested him?</i>). I think this model is fairly good as it stands since there's technically 162 total options. This model is already one and a half times better than picking Jinx every time and is 75 times better than picking a champion at random. But I would like it to at least be better than 50%. Can that be too much to ask for? (<i>Spoilers: It was a lot to ask for</i>)</p>

									<h2>Final Model</h2>

									<p>So I guess 50% is my target accuracy. I'll add some features to make it better. The model currently has no way to quantify how good any given champion is and the state of the meta. In order to inform the model about the quality of the champions being selected, I added two new features called total presence and average win rate. To impliment both, I used a function transformer and created a transforming function. Both work in a similar manner. I took the raw dataset, and computed the presence (being the proportion of games a champion is played in) and the win rate of the champions. With these, I used a column transformer to pass in subsets of the dataset X, which would then encode the champions in the subset to their presence and win rate values, finally summing them row-by-row. I used these to create four new features: teammate win rate, teammate presence, opponent presence, and banned presence.</p>

									<p>I decided to include these because I figured the algorithm could do with some external, performance data. Idea being being that telling the model which champions were more popular could help it make its decisions. Maybe a team with really low presence would be more likely to pick a champion with lower presence as well. Same idea for the win rate, as perhaps a low win rate team on paper would select a different champion than a team with a higher win rate.</p>

									<p>I did another thing to make my testing a little better. I decided to impliment my own version of one hot encoding in order to significantly reduce the dimensionality and make my code run a lot quicker, which would prove to be very necessary. I wrote a bit that would one hot encode sections together. So instead of ten bans taking up 1630 features, since each column had to be one hot encoded individually, those ten bans only took up 163. Ultimately, I went from 2652 features down to less than 500. I do think I lost a little bit of accuracy, since the order of the columns technically do encode information, such as the order of the teammates/opponents indicating position, but I figured that the machine could do without.</p>

									<p>The story behind which model I ended up choosing is kind of funny. I tried a couple in my baseline being a decision tree, random forest, and gradient boosting classifier. The gradient boosting classifier actually performed the best right out of the box, but ended up taking ten minutes to run. I did not have that kind of time (<i>foreshadowing</i>). I decided on a random forest and so I hit the ground running with a grid search. I looked at the documentation and grabbbed the top few hyperparameters and got my search to start. I ran it with five folds, what could possibly go wrong? Well, 405 fits could go wrong. Fortunately for me, they didn't. Unfortunately for me, this took nine hours. I will say, I got a good night's rest. Why would I do this? I got a new computer, that's why.</p>
									
									<p>This is where the comedy kicks in. Right before I hop in the shower the night before, I look up online "Best classifiers for multiclass categorization", and there I find it, staring back at me: neural network. That seems cool. Too bad I'm already three hours in to my grid search.</p>

									<p>I wake up in the morning to a horrible sight. My best parameters ran just below 50%. In fact, it only got up to 49%. That was so sad to see. Well, I decided screw it, I'll try the MLP classifier, not that I really have any idea what it's doing (and neither does anybody, really). Out of the box, it scores really well, already at 48%, and I think, I have four hours that I'll be at work for, that sounds like plenty of time. So before I left that morning, I set up a search for my hyperparameters once again.</p>

									<p>This time, each MLP classifier was taking much longer, but I figured that since neural networks are so cool, it was worth going through (just to say that I have done it). Since I didn't really have as good of a clue what the hyperparameters were doing for this classifier, I used a randomized search to find the best parameters. I set it to test fifty combinations, and I set off to work. When I got back, I saw that it ran for seven hours and settled on the following prameters:
										<ul>
										<li>Activation: tanh</li>
										<li>Alpha: 0.0005</li>
										<li>Batch Size: 71</li>
										<li>Hidden Layer Sizes: (100, 100)</li>
										<li>Learning Rate: Constant</li>
										<li>Solver: sdg</li>
										</ul>
									Well, how'd it do? A NICE 58%! That's way better than the 50% target! I'm quite happy with this. I think the primary driver of the success was switching to an MLP classifier. To its credit, however, the baseline wasn't too far from the random forest's baseline. It just had a lot more room for improvement. I think it could be even higher if I grid searched even more hyperparameters. Unfortunately, I don't have that much time anymore.</p>

									<h2>Fairness Analysis</h2>
									
									<p>Well, that was cool! How fair is the model, though? Well, we can find out through a quick (hour and a half long) permutation test. I decided to check and see if the model has accuracy parity between the major four regions (China, Korea, Europe, and NA) and the rest of the leagues. The reason I think it might not is because the level in these four regions is just much higher than that of the other regions (barring "leagues" like MSI and WCS which are actually the biggest international LAN tournaments). I think, based solely on the eye test, that the major regions might have higher accuracy due to having more predictable picks. Let's find out.</p>

									<p>So more clearly, my groups are Group in-big-four and Group out-of-big-four. I'll test this by measuring difference of accuracies from big-four to not-big-four. I'm going with an alpha of 0.05. My hypotheses are as follows:
										<ul>
										<li>Null Hypothesis: The model is fair and achieves accuracy parity between games in and out of the big four regions</li>
										<li>Alternative Hypothesis: The model is unfair and does not achieve accuracy parity between games in and out of the big four regions. The accuracy in the big four regions is higher than that of non-big four leagues.</li>
										</ul>
									Running the split and finding the existing difference between accuracies was not hopeful. Within big four had an accuracy of 81%. Outside had an accuracy of 70%. Yikes. Is it even worth running the actual test?
									</p>

									<p>Predicting each time takes about a minute. So in order to keep it within a reasonable amount of time, I only did 100 permutations. Don't worry, that was plenty enough. Whereas the difference in accuracy proportions is 0.11, the maximum test statistic of the 100 is 0.02 (mean being 0.0002). The p-value of this test is &lt;0.05. I think it's safe to say that we can reject the null hypothesis.</p>

									<iframe src="../assets/data/lol2permtest.html" width=100% height=400 frameBorder=0></iframe>

									<h2>Final Thoughts</h2>

									<p>This was pretty fun. Also, not very difficult at all! There's tons of potential for something like this. Plenty of League of Legends websites already exist to tell you who to play that are much more sophisticated, so maybe there's not too much more here for me. However, this has opened the door to many (MANY!) other potential things. I read about this person who created a Rocket League game-state evaluator by training a logistic regression model to predict who would score the next goal from any given position, and used the machine's confidence as the evaluation. I haven't read about that in a couple years, so I might try doing something similar myself. Anywho, hopefully this upcoming summer will be eventful for me!</p>
									
									<p><i>Christopher Lum</i></p>
									
									<h3>PS: Gameshow!</h3>

									<p>If you've made it this far, ily &lt;3. Remember how my friend said he thought he could do about 30%? Well, I tested him! I told him and a couple friends about my model's success and we had the idea of asking him to predict the bot laner based off of the 19 champions, patch, and league. I was intruiged as well, since I don't follow League as much as he or my other friend do, so I didn't really know how easy this task was.</p>

									<p>Picture the five of us, taking a break (from League, of course) to play my little makeshift gameshow. Basically, I presented them a row of X and asked them to guess. They played ten total rounds, resulting in 40 human predictions. My friend, who has followed League for over eight years, got a big donut! Two of them got 2/10, and the fourth also got zero. In total, the humans were at 10%. A lot worse than my model! Also, embarassingly, worse than just guessing Jinx the entire time, which is pretty much where one of those 2/10s came from. Silly them, should've looked at 12,000 games to practice. Their loss. Thanks for watching, that's the show!</p>




								</div>
								
							</section>

					</div>

				<!-- Footer -->
				<footer id="footer">
					<section>
						<h2>About Me</h2>
						<p>My goal is to use data to effectively share stories and to solve and communicate optimal solutions for whatever lies ahead. Feel free to contact me if you would like to work together.</p>
					</section>
					<section>
						<h2>Contact</h2>
						<dl class="alt">
							<dt>City</dt>
							<dd>San Diego, CA</dd>
							<dt>Email</dt>
							<dd>cslum[at]ucsd.edu</dd>
						</dl>
						<ul class="icons">
							<li><a href="https://github.com/ch-lum" class="icon brands fa-github alt" target="_blank" rel="noopener noreferrer"><span class="label">GitHub</span></a></li>
							<li><a href="https://www.linkedin.com/in/ch-lum/" class="icon brands fa-linkedin alt" target="_blank" rel="noopener noreferrer"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://vsco.co/ch-lum/gallery" class="icon solid fa-camera-retro alt" target="_blank" rel="noopener noreferrer"><span class="label">VSCO</span></a></li>
						</ul>
					</section>
					<p class="copyright">Christopher Lum | <a href="#">Back to top</a>.</p>
				</footer>

			</div>

		<!-- Anchor -->
			<img src="../images/footerimage.png" style="width:100%; margin-top: -10em; pointer-events: none; user-select: none;">

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>